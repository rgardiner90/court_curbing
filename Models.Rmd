---
title: "Court Curb Analysis"
author: "Richard G. Gardiner"
date: "10/24/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Data and Packages

```{r, packages, message=FALSE}
library(tidyverse)
library(readxl)
library(grid)
library(gridExtra)
library(lme4)
library(MASS)
library(modelr)

theme_set(theme_light())
```


```{r}
count_data <- read_csv("count_data.csv")
gavelCultureControl <- read_csv("gavelCultureControl.csv")
gavelFull <- read_csv("gavelFull.csv")
professionalization <- read_csv("ncsl professionalization.csv")
```


# Iniital Models

```{r}
curbs.poisson <- glm(curbs ~ Moralistic + Traditionalistic + RepublicanLegslature + SplitLegislature + court_lower_dist + court_upper_dist + retention + partisan + nonpartisan + court_gov_dist + court_lower_dist + court_upper_dist + partisan_ideology_upper + partisan_ideology_lower + nonpartisan_ideology_upper + nonpartisan_ideology_lower + retention_ideology_lower + retention_ideology_upper + Professionalization,
                     family = poisson(link = log),
                     data = count_data)

summary(curbs.poisson)

exp(-0.675867) # need exponent to be able to make a good interpreptation.
# this one, for example, shows us that (for the goefficient on retention elections) that by switching between appointed to retention we see about a 49% drop in curbs

exp(curbs.poisson$coefficients[-1])
```

Now I will run a Negative Binomial model to check to see how this model compares and to see if there is a problem of overdispersion in the poisson

```{r}
curbs1.nb <- glm.nb(curbs ~ Moralistic + Traditionalistic + RepublicanLegslature + SplitLegislature + court_lower_dist + court_upper_dist + retention + partisan + nonpartisan + court_gov_dist + partisan_ideology_upper + partisan_ideology_lower + nonpartisan_ideology_upper + nonpartisan_ideology_lower + retention_ideology_lower + retention_ideology_upper + Professionalization,
                     data = count_data)

summary(curbs1.nb)
```


### Elected and Appointed 

This section is looking at elected and appointed versus the broken down variable (with variations).  First, I need to create a variable that can capture elected versus appointed

```{r}
curbs.elected.nb <- glm.nb(curbs ~ elected,
                     data = count_data)
summary(curbs.elected.nb) # not significant
```


### Up until 2012 data (problems with ideology)

Getting data without the other years
```{r}
count_data2 <- gavelCultureControl %>%
  filter(!(Year %in% c("2007", "43147", "2013", "2014", "2015", "2016", "2017", "2018"))) %>% # filtering out bad data
  group_by(State, Year) %>% 
  mutate(curbs = sum(curbing)) %>%
  distinct(State, Year, .keep_all = TRUE) %>%
  arrange(State, Year) 
  
count_data2
```

Adding in new variables
```{r}
count_data2$elected <- ifelse(count_data2$Elected == "Elected", 1, 0)
count_data2$partisan <- ifelse(count_data2$MoreDefined == "Partisan", 1, 0)
count_data2$nonpartisan <- ifelse(count_data2$MoreDefined == "Nonpartisan", 1, 0)
count_data2$retention <- ifelse(count_data2$MoreDefined == "Retention", 1, 0)

count_data2$elected_ideology_gov <- count_data2$elected * count_data2$court_gov_dist
count_data2$elected_ideology_upper <- count_data2$elected * count_data2$court_upper_dist
count_data2$elected_ideology_lower <- count_data2$elected * count_data2$court_lower_dist

count_data2$partisan_ideology_gov <- count_data2$partisan * count_data2$court_gov_dist
count_data2$partisan_ideology_upper <- count_data2$partisan * count_data2$court_upper_dist
count_data2$partisan_ideology_lower <- count_data2$partisan * count_data2$court_lower_dist

count_data2$nonpartisan_ideology_gov <- count_data2$nonpartisan * count_data2$court_gov_dist
count_data2$nonpartisan_ideology_upper <- count_data2$nonpartisan * count_data2$court_upper_dist
count_data2$nonpartisan_ideology_lower <- count_data2$nonpartisan * count_data2$court_lower_dist

count_data2$retention_ideology_gov <- count_data2$retention * count_data2$court_gov_dist
count_data2$retention_ideology_upper <- count_data2$retention * count_data2$court_upper_dist
count_data2$retention_ideology_lower <- count_data2$retention * count_data2$court_lower_dist

count_data2 <- left_join(count_data2, professionalization, by = c("Fullstate" = "State"))

table(count_data2$Year, count_data2$Fullstate)
```



```{r}
curbs2.elected1.nb <- glm.nb(curbs ~ elected + court_upper_dist + court_lower_dist,
                     data = count_data2)
summary(curbs2.elected1.nb) # upper distance is again distinct
```

```{r}
curbs2.elected2.nb <- glm.nb(curbs ~ elected + court_upper_dist + court_lower_dist + elected_ideology_lower + elected_ideology_upper,
                     data = count_data2)
summary(curbs2.elected2.nb) # nothing significant
```

```{r}
curbs2.elected3.nb <- glm.nb(curbs ~ elected + court_upper_dist + court_lower_dist + elected_ideology_lower + elected_ideology_upper + Moralistic + Traditionalistic + RepublicanLegslature + SplitLegislature +  Professionalization,
                     data = count_data2)
summary(curbs2.elected3.nb)
```


# Post-Steigerwalt Meeting (End of November 2018)

Suggestions from Steigerwalt:

* What percentage of all legislation that year that deal with courts are court curbing bills (4 court curbing out of 20 bills)?  Run a regression with that
* Do unified/divided instead of the republican/democratic/split
* map out upper and partisan interaction (plot it out).  This applies, right now, to the count models
* Question: is the full model overfitted?

## Doing Unified government

Full model
```{r}
curbs_unified.nb <- glm.nb(curbs ~ Moralistic + Traditionalistic + unified + court_lower_dist + court_upper_dist + elected + elected_ideology_upper + elected_ideology_lower + Professionalization,
                     data = count_data2)

summary(curbs_unified.nb) # traditionalistic, professionalization, and unified are significant and positive.
```


## Percentage of all legislation that year
```{r}
percent_curbing <- gavelCultureControl %>%
  group_by(Fullstate, Year) %>%
  summarise(percentage = sum(curbing)/n()) 
  
percent_curbing <- percent_curbing %>%
  left_join(count_data, by = c("Fullstate", "Year")) %>%
  dplyr::select(-5:-6, -9:-17) 

percent_curbing
```

One of the first things I notice is that Alaska in 2017 has a score of 1, but that is really only because in 2017 there is only one bill that is dealing with the courts and that is a curbing bill.  How should that really be counted?  It feels like there should be some kind of weighting measure, but will have to discuss with Steigerwalt.
```{r}
gavelCultureControl %>%
  filter(Fullstate == "Alaska" & Year == 2017)
```



It appears, from the graph below, that there is a slight difference in the means between the two.  A simple t-test should show us that.
```{r}
percent_curbing %>%
  filter(!is.na(Elected)) %>%
  ggplot() +
    geom_histogram(aes(percentage, y = ..density.., fill = Elected)) +
    facet_wrap(~ Elected)
```


A simple t-test shows that there is a statistically significant differnece between the two and that the mean of Elected states is significantly higher than the mean of appointed courts.
```{r}
t.test(percentage ~ Elected, data = percent_curbing)
```

adding in unified government.  This would constitute the full model
```{r}
percent_curbing <- percent_curbing %>%
  mutate(unified = ifelse(SplitLegislature == 0, 1, 0))
```

Takeaway: Elected really is significant and robust to multiple variations.

```{r}
percent_curbing2 <- percent_curbing %>%
  filter(!is.na(Elected)) %>%
  filter(!(Year %in% c("2007", "43147", "2013", "2014", "2015", "2016", "2017", "2018")))  # filtering out bad data

percent_curbing2

percent_md_6 <- lm(percentage ~ elected + court_upper_dist + court_lower_dist + elected_ideology_upper + elected_ideology_lower +
                     Moralistic + Traditionalistic + Professionalization + unified, 
                    data = percent_curbing2) # full model, not good

percent_md_7 <- lm(percentage ~ elected, 
                    data = percent_curbing2)
summary(percent_md_7)

percent_md_8 <- lm(percentage ~ elected + court_upper_dist + court_lower_dist, 
                    data = percent_curbing2)
summary(percent_md_8)

percent_md_9 <- lm(percentage ~ elected + court_upper_dist + court_lower_dist + elected_ideology_upper + elected_ideology_lower, 
                    data = percent_curbing2)
summary(percent_md_9) # nothing sig
```



# Final Models:

I will use these as the official models with the broken down models in an appendix.






## Final Models - Percentage DV
```{r}
## Shorter years
summary(percent_md_7) # just elected
summary(percent_md_8) # elected and ideology
summary(percent_md_9) # elected interacted with ideology nothing sig
summary(percent_md_6) # full model with ideology and shorter years


## Full years, no ideology
percent_md_no_id_1 <- lm(percentage ~ elected + Moralistic + Traditionalistic + Professionalization + unified, data = percent_curbing)
summary(percent_md_no_id_1) # full model (excluding ideology)

percent_md_no_id_2 <- lm(percentage ~ elected, data = percent_curbing)
summary(percent_md_no_id_2) # sig, by itself
```


### Predictions

```{r}
percent_curbing2_predictions <- percent_curbing2 %>%
  add_predictions(percent_md_6)

ggplot(data = percent_curbing2_predictions) +
  geom_boxplot(aes(x = as.factor(Professionalization), y = pred)) +
  xlab("Level of Professionalization") +
  ylab("Predicted Proportion")

# ggsave("Prof and proportion.png")

ggplot(data = percent_curbing2_predictions) +
  geom_boxplot(aes(x = as.factor(elected), y = pred)) +
  ylab("Predicted Proportion") +
  xlab("Elected Versus Appointed") +
  scale_x_discrete(labels = c("0" = "Appointed", "1" = "Elected"))

# ggsave("elected and prop.png")

j <- ggplot(data = percent_curbing2_predictions) +
  geom_point(aes(x = court_lower_dist, y = pred)) +
  ylab("Predicted Proportion") +
  xlab("Ideological Distance from Lower Chamber")

k <- ggplot(data = percent_curbing2_predictions) +
  geom_point(aes(x = court_upper_dist, y = pred)) +
  ylab("Predicted Proportion") +
  xlab("Ideological Distance from Upper Chamber")
  
grid.arrange(j, k)


## without ideology
percent_curbing_predictions <- percent_curbing %>%
  add_predictions(percent_md_no_id_1)

ggplot(data = percent_curbing_predictions) +
  geom_boxplot(aes(x = as.factor(Professionalization), y = pred)) +
  xlab("Level of Professionalization") +
  ylab("Predicted Proportion")


ggplot(data = percent_curbing_predictions) +
  geom_boxplot(aes(x = as.factor(elected), y = pred)) +
  xlab("Elected Versus Appointed") +
  ylab("Predicted Proportion") +
  scale_x_discrete(labels = c("0" = "Appointed", "1" = "Elected"))

```




## Final Models - Count

```{r}
# shorter years (with ideology included)
summary(curbs_unified.nb) # full model
exp(curbs_unified.nb$coefficients)


curbs2.elected0.nb <- glm.nb(curbs ~ elected, data = count_data2)
summary(curbs2.elected0.nb) # just elected

summary(curbs2.elected1.nb) # elected and ideology (no iteractions)
summary(curbs2.elected2.nb) # elected and ideology (interacted)

exp(curbs2.elected1.nb$coefficients)

# longer years (no ideology)
summary(curbs.elected.nb) # just elected

curbs.elected.unified.nb <- glm.nb(curbs ~ Moralistic + Traditionalistic + unified +  elected + Professionalization,
                     data = count_data)
summary(curbs.elected.unified.nb) # full model
exp(curbs.elected.unified.nb$coefficients)
```



### Adding predictions for Count Data

```{r}
count_data2_predictions <- count_data2 %>%
  add_predictions(curbs_unified.nb)

ggplot(data = count_data2_predictions) +
  geom_boxplot(aes(x = as.factor(Professionalization), y = pred)) +
  ylab("Predicted Count") +
  xlab("Level of Professionalization")

ggplot(data = count_data2_predictions) +
  geom_boxplot(aes(x = as.factor(elected), y = pred)) +
  ylab("Predicted Count") +
  xlab("Elected Versus Appointed") +
  scale_x_discrete(labels = c("0" = "Appointed", "1" = "Elected"))

l <- ggplot(data = count_data2_predictions) +
  geom_point(aes(x = court_lower_dist, y = pred)) +
  ylab("Predicted Count") +
  xlab("Ideological Distance from Lower Chamber")


m <- ggplot(data = count_data2_predictions) +
  geom_point(aes(x = court_upper_dist, y = pred)) +
  ylab("Predicted Count") +
  xlab("Ideological Distance from Upper Chamber")

grid.arrange(l, m)

grid <- count_data2 %>%
  data_grid(court_upper_dist, .model = curbs_unified.nb) %>%
  add_predictions(curbs_unified.nb)


ggplot(grid, aes(court_upper_dist, pred)) +
  geom_point() +
  ylab("Predicted Count") +
  xlab("Simulated Ideological Distance from Upper Chamber")

# ggsave("count of bills and proportions.png")


# Now without ideology 
count_data_predictions <- count_data %>%
  add_predictions(curbs.elected.unified.nb) 

# added jitter because it was so weird
ggplot(data = count_data_predictions) +
  geom_boxplot(aes(x = as.factor(Professionalization), y = pred)) +
  ylab("Predicted Count") +
  xlab("Level of Professinalization") +
  geom_jitter(aes(x = as.factor(Professionalization), y = pred))

ggplot(data = count_data_predictions) +
  geom_boxplot(aes(x = as.factor(elected), y = pred)) +
  ylab("Predicted Count") +
  xlab("Elected Versus Appointed") +
  scale_x_discrete(labels = c("0" = "Appointed", "1" = "Elected"))
  
```






## Model diagnostics

### No Ideology:
Adding the predicted and residual values
```{r}
percent_curbing  <- percent_curbing %>%
  filter(!is.na(Elected)) %>%
  add_predictions(percent_md_no_id_1) %>%
  add_residuals(percent_md_no_id_1) %>%
  filter(!is.na(resid))
```

Checking normal distribution.  It is pretty good, but there are some outliers at the far right.  The mean of the residual is: `r mean(percent_curbing$resid)` which is rather small. 
```{r}
ggplot(percent_curbing, aes(resid)) +
  geom_histogram()
```

```{r}
plot(percent_md_no_id_1)
```


### Shorter years, but ideology

```{r}
percent_curbing2  <- percent_curbing2 %>%
  filter(!is.na(Elected)) %>%
  add_predictions(percent_md_6) %>%
  add_residuals(percent_md_6) %>%
  filter(!is.na(resid))
```


Checking normal distribution.  It is pretty good, but there are some outliers at the far right.  The mean of the residual is: `r mean(percent_curbing2$resid)` which is rather small. 
```{r}
ggplot(percent_curbing2, aes(resid)) +
  geom_histogram()
```

```{r}
plot(percent_md_6)
```

It does struggle on the outer edges of X.


### Concerns with the proportion DV

I am worried that the proportion of all court curbing legislation in one year for a given state is so small that changing the numerator by 1 will produce wild swings.  Let's check this out:

```{r}
d <- ggplot(percent_curbing) +
  geom_histogram(aes(x = percentage, y = ..density..)) +
  labs(x = "Proportion of Bills that Curb Courts")
```

The chart above shows the distribution of proportions.  This is somewhat unsuripring in the distribution, but now lets look at the total number of legislation in a given year.

```{r}
bills_state_year <- gavelFull %>%
  group_by(Fullstate, Year) %>%
  count()
  
e <- ggplot(bills_state_year) +
  geom_histogram(aes(x = n, y = ..density..)) +
  labs(x = "Number of Bills in a Year")

gridExtra::grid.arrange(d, e, ncol = 2)
```

There graph shows that while there are instances of a large number of legislation concerning the court, the median is `r median(bills_state_year$n)` with a mode of 1.  


## Testing out the idea of splitting up the electoral variable

This is primarily in response to the poor showing of election.
```{r}
test <- glm.nb(curbs ~ Moralistic + Traditionalistic + unified +  partisan + nonpartisan + retention + Professionalization,
                     data = count_data)
summary(test)

test2 <- glm.nb(curbs ~ partisan + nonpartisan + retention,
                     data = count_data)
summary(test2)

```



# Variations 

This section is the variations to try to get an idea of what may be causing this problem of not finding significance.  

## Ideological Distance

The first variation is ideological distance:

First thing I need is a new ideology variable.  I found a resource that appears to have a lot of judge data: https://www.acslaw.org/analysis/reports/partisan-justice/

Here I am loading the data and grabbing only the important variables
```{r}
later_judges <- read_excel("later judges.xlsx")

later_judges <- later_judges %>%
  dplyr::select(statename, `decision year`, `judge's name`, 
                `judge's political party`, `years to next election`)
```

I am amking a lot of decisions on this one.  The beginning is just cleaning up the data, and making it easier to manipuate.  Toward the middle, I am forcing NAs for multiple years and then filtering down and filtering up as necessary to remove missing data.  Nice trick, but assumes that things are changing much.
```{r}
judges <- later_judges %>%
  distinct() %>%
  rename(year = 2,
         judges_name = 3,
         judges_party = 4,
         years_to_election = 5) %>%
  mutate(democrat = ifelse(judges_party == "D", 1, 0)) %>%
  dplyr::select(-judges_name, -judges_party) %>%
  group_by(statename, year) %>%
  summarize(mean_dem = mean(democrat)) %>%
  na.omit() %>%
  mutate(dem_majority = ifelse(mean_dem >= 0.5, 1, 0)) %>%
  dplyr::select(-mean_dem) %>%
  filter(year > 2007) %>%
  spread(year, dem_majority) %>% # nifty trick to create nas
  mutate(`2015` = NA, 
         `2016` = NA, 
         `2017` = NA, 
         `2018` = NA) %>%
  gather(year, dem_majority, -statename) %>%
  arrange(statename, year) %>%
  fill(dem_majority) %>% # filling in missing data
  group_by(statename) %>%
  fill(dem_majority, .direction = "up") %>% # filling in last missing data
  mutate(year = as.numeric(year))
```

Now I am reading in the data used in the overrides chapter that has legislative control for many years.  I then join it and create teh variable `ideological congruent`
```{r}
partisan_control <- read_csv("~/Google Drive/school/Dissertation/Data/override_chapter/data/partisan_control.csv") %>%
  filter(Year >= 2008) %>%
  dplyr::select(-republican_court, -ideologically_similary)

ideology <- partisan_control %>%
  left_join(judges, by = c("State" = "statename", "Year" = "year")) %>%
  mutate(repub_majority = ifelse(dem_majority == 0, 1, 0),
         ideological_congruent = ifelse(repub_majority == RepublicanLegslature, 1, 0)) %>%
  dplyr::select(State, Year, ideological_congruent)
```


### Proportion of curbs

Now I am trying out the model for proportion of curbs:  Short story is that after a simple model, nothing is significant.
```{r}
percent_curbing_ideology <- percent_curbing2 %>%
  left_join(ideology, by = c("Fullstate" = "State", "Year"))

pct_new_ideology_1 <- lm(percentage ~ elected, 
                    data = percent_curbing_ideology)
summary(pct_new_ideology_1)

pct_new_ideology_2 <- lm(percentage ~ elected + ideological_congruent, 
                    data = percent_curbing_ideology)
summary(pct_new_ideology_2) # nothing sig

pct_new_ideology_3 <- lm(percentage ~ elected + ideological_congruent + elected*ideological_congruent, 
                    data = percent_curbing_ideology)
summary(pct_new_ideology_3) # nothing sig
```

What if I take out those nasty assumptions especially toward the end?  (nothing changes)
```{r}
pct_curb_ideo_filter <- percent_curbing_ideology %>%
  filter(Year < 2015)

pct_filter_ideology_1 <- lm(percentage ~ elected, 
                    data = pct_curb_ideo_filter)
summary(pct_filter_ideology_1) # sig

pct_filter_ideology_2 <- lm(percentage ~ elected + ideological_congruent, 
                    data = pct_curb_ideo_filter)
summary(pct_filter_ideology_2) # nothing sig

pct_filter_ideology_3 <- lm(percentage ~ elected + ideological_congruent + elected*ideological_congruent,
                    data = pct_curb_ideo_filter)
summary(pct_filter_ideology_3) # nothing sig
```


### Count models

```{r}
curbs_data_new_ideology <- count_data2 %>%
  left_join(ideology, by = c("Fullstate" = "State", "Year")) 

curbs_new_data_1 <- glm.nb(curbs ~elected, data = curbs_data_new_ideology)
summary(curbs_new_data_1) # not sig!!!

curbs_new_data_2 <- glm.nb(curbs ~ elected + ideological_congruent, data = curbs_data_new_ideology)
summary(curbs_new_data_2) # ideologically congruent is significant

curbs_new_data_3 <- glm.nb(curbs ~ elected + ideological_congruent + 
                             elected*ideological_congruent, data = curbs_data_new_ideology)
summary(curbs_new_data_3) # still significant

curbs_new_data_4 <- glm.nb(curbs ~ elected + ideological_congruent + 
                             elected*ideological_congruent + Moralistic + 
                             Traditionalistic + unified + Professionalization,
                     data = curbs_data_new_ideology)
summary(curbs_new_data_4) # only unified and professional is still sig
```


What if I take out those nasty assumptions about the later years?

```{r}
curb_ideo_filter <- curbs_data_new_ideology %>%
  filter(Year < 2015)

curbs_ideo_filter_1 <- glm.nb(curbs ~elected, data = curb_ideo_filter)
summary(curbs_ideo_filter_1) # not sig!!!

curbs_ideo_filter_2 <- glm.nb(curbs ~elected + ideological_congruent, data = curb_ideo_filter)
summary(curbs_ideo_filter_2) # ideo is sig

curbs_ideo_filter_3 <- glm.nb(curbs ~elected + ideological_congruent + 
                                elected*ideological_congruent, data = curb_ideo_filter)
summary(curbs_ideo_filter_3) # ideo is sig

curbs_ideo_filter_4 <- glm.nb(curbs ~elected + ideological_congruent + 
                                elected*ideological_congruent + unified +
                                Moralistic + Traditionalistic + Professionalization,
                              data = curb_ideo_filter)
summary(curbs_ideo_filter_4) # just unified and professionalization
```


