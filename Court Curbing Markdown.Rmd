---
title: "Court Curb Analysis"
author: "Richard G. Gardiner"
date: "10/24/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Data and Packages

```{r, packages, message=FALSE}
library(tidyverse)
library(readxl)
library(grid)
library(gridExtra)
library(lme4)
```


```{r}
count_data <- read_csv("count_data.csv")
gavelCultureControl <- read_csv("gavelCultureControl.csv")
gavelFull <- read_csv("gavelFull.csv")
professionalization <- read_csv("ncsl professionalization.csv")
```


# Iniital Models

```{r}
curbs.poisson <- glm(curbs ~ Moralistic + Traditionalistic + RepublicanLegslature + SplitLegislature + court_lower_dist + court_upper_dist + retention + partisan + nonpartisan + court_gov_dist + court_lower_dist + court_upper_dist + partisan_ideology_upper + partisan_ideology_lower + nonpartisan_ideology_upper + nonpartisan_ideology_lower + retention_ideology_lower + retention_ideology_upper + Professionalization,
                     family = poisson(link = log),
                     data = count_data)

summary(curbs.poisson)

exp(-0.675867) # need exponent to be able to make a good interpreptation.
# this one, for example, shows us that (for the goefficient on retention elections) that by switching between appointed to retention we see about a 49% drop in curbs

exp(curbs.poisson$coefficients[-1])
```

Now I will run a Negative Binomial model to check to see how this model compares and to see if there is a problem of overdispersion in the poisson

```{r}
library(MASS)

curbs1.nb <- glm.nb(curbs ~ Moralistic + Traditionalistic + RepublicanLegslature + SplitLegislature + court_lower_dist + court_upper_dist + retention + partisan + nonpartisan + court_gov_dist + partisan_ideology_upper + partisan_ideology_lower + nonpartisan_ideology_upper + nonpartisan_ideology_lower + retention_ideology_lower + retention_ideology_upper + Professionalization,
                     data = count_data)

summary(curbs1.nb)
```

The Theta parameter (with the accompanying standard error) tells us that overdispersion is present and thus we should not be using a poisson model.  The Negative Binomial also has a lower AIC than the poisson giving even more evidence that the negaitve binomial is the better model.

I forgot until now that I want to remove the governor from the model that looks at all bills because they are not really in the calculation for this.  The code below is a new model excluding the governor.

```{r}
curbs2.nb <- glm.nb(curbs ~ Moralistic + Traditionalistic + RepublicanLegslature + SplitLegislature + court_lower_dist + court_upper_dist + retention + partisan + nonpartisan + partisan_ideology_upper + partisan_ideology_lower + nonpartisan_ideology_upper + nonpartisan_ideology_lower + retention_ideology_lower + retention_ideology_upper + Professionalization,
                     data = count_data)

summary(curbs2.nb)
```


```{r}
library(modelr)

grid <- count_data %>%
  data_grid(retention_ideology_upper, .model = curbs2.nb) %>%
  add_predictions(curbs2.nb)
  

grid

ggplot(grid, aes(retention_ideology_upper, pred)) +
  geom_point()
```

```{r}
curbs2.nb <- glm.nb(curbs ~ Moralistic + Traditionalistic + RepublicanLegslature + SplitLegislature + court_lower_dist + court_upper_dist + retention + partisan + nonpartisan + partisan_ideology_upper + partisan_ideology_lower + nonpartisan_ideology_upper + nonpartisan_ideology_lower + retention_ideology_lower + retention_ideology_upper + Professionalization,
                     data = count_data)

summary(curbs2.nb)
```

# Variations 

```{r}
# bare bones model: 
curbs3.nb <- glm.nb(curbs ~ retention + partisan + nonpartisan,
                     data = count_data)
summary(curbs3.nb)
```

```{r}
curbs4.nb <- glm.nb(curbs ~ court_lower_dist + court_upper_dist + retention + partisan + nonpartisan,
                     data = count_data)
summary(curbs4.nb)
```

```{r}
curbs5.nb <- glm.nb(curbs ~ court_lower_dist + court_upper_dist + retention + partisan + nonpartisan + partisan_ideology_upper + partisan_ideology_lower + nonpartisan_ideology_upper + nonpartisan_ideology_lower + retention_ideology_lower + retention_ideology_upper,
                     data = count_data)
summary(curbs5.nb)
```

### Elected and Appointed 

This section is looking at elected and appointed versus the broken down variable (with variations).  First, I need to create a variable that can capture elected versus appointed

```{r}
curbs.elected.nb <- glm.nb(curbs ~ elected,
                     data = count_data)
summary(curbs.elected.nb) # not significant
```

```{r}
curbs.elected1.nb <- glm.nb(curbs ~ elected + court_upper_dist + court_lower_dist,
                     data = count_data)
summary(curbs.elected1.nb) # again, the upper house ideological distance variable is significant
```

```{r}
curbs.elected2.nb <- glm.nb(curbs ~ elected + court_upper_dist + court_lower_dist + elected_ideology_lower + elected_ideology_upper,
                     data = count_data)
summary(curbs.elected2.nb) # upper is significant still
```

```{r}
curbs.elected3.nb <- glm.nb(curbs ~ elected + court_upper_dist + court_lower_dist + elected_ideology_lower + elected_ideology_upper + Moralistic + Traditionalistic + RepublicanLegslature + SplitLegislature +  Professionalization,
                     data = count_data)
summary(curbs.elected3.nb)
```


### Up until 2012 data (problems with ideology)

Getting data without the other years
```{r}
count_data2 <- gavelCultureControl %>%
  filter(!(Year %in% c("2007", "43147", "2013", "2014", "2015", "2016", "2017", "2018"))) %>% # filtering out bad data
  group_by(State, Year) %>% 
  mutate(curbs = sum(curbing)) %>%
  distinct(State, Year, .keep_all = TRUE) %>%
  arrange(State, Year) 
  
count_data2
```

Adding in new variables
```{r}
count_data2$elected <- ifelse(count_data2$Elected == "Elected", 1, 0)
count_data2$partisan <- ifelse(count_data2$MoreDefined == "Partisan", 1, 0)
count_data2$nonpartisan <- ifelse(count_data2$MoreDefined == "Nonpartisan", 1, 0)
count_data2$retention <- ifelse(count_data2$MoreDefined == "Retention", 1, 0)

count_data2$elected_ideology_gov <- count_data2$elected * count_data2$court_gov_dist
count_data2$elected_ideology_upper <- count_data2$elected * count_data2$court_upper_dist
count_data2$elected_ideology_lower <- count_data2$elected * count_data2$court_lower_dist

count_data2$partisan_ideology_gov <- count_data2$partisan * count_data2$court_gov_dist
count_data2$partisan_ideology_upper <- count_data2$partisan * count_data2$court_upper_dist
count_data2$partisan_ideology_lower <- count_data2$partisan * count_data2$court_lower_dist

count_data2$nonpartisan_ideology_gov <- count_data2$nonpartisan * count_data2$court_gov_dist
count_data2$nonpartisan_ideology_upper <- count_data2$nonpartisan * count_data2$court_upper_dist
count_data2$nonpartisan_ideology_lower <- count_data2$nonpartisan * count_data2$court_lower_dist

count_data2$retention_ideology_gov <- count_data2$retention * count_data2$court_gov_dist
count_data2$retention_ideology_upper <- count_data2$retention * count_data2$court_upper_dist
count_data2$retention_ideology_lower <- count_data2$retention * count_data2$court_lower_dist

count_data2 <- left_join(count_data2, professionalization, by = c("Fullstate" = "State"))

table(count_data2$Year, count_data2$Fullstate)
```

```{r}
curbs_2.nb <- glm.nb(curbs ~ retention + partisan + nonpartisan,
                     data = count_data2)
summary(curbs_2.nb) # nothing significant
```

```{r}
curbs2.elected1.nb <- glm.nb(curbs ~ elected + court_upper_dist + court_lower_dist,
                     data = count_data2)
summary(curbs2.elected1.nb) # upper distance is again distinct
```

```{r}
curbs2.elected2.nb <- glm.nb(curbs ~ elected + court_upper_dist + court_lower_dist + elected_ideology_lower + elected_ideology_upper,
                     data = count_data2)
summary(curbs2.elected2.nb) # nothing significant
```

```{r}
curbs2.elected3.nb <- glm.nb(curbs ~ elected + court_upper_dist + court_lower_dist + elected_ideology_lower + elected_ideology_upper + Moralistic + Traditionalistic + RepublicanLegslature + SplitLegislature +  Professionalization,
                     data = count_data2)
summary(curbs2.elected3.nb)
```

```{r}
curbs2_full.nb <- glm.nb(curbs ~ Moralistic + Traditionalistic + RepublicanLegslature + SplitLegislature + court_lower_dist + court_upper_dist + retention + partisan + nonpartisan + partisan_ideology_upper + partisan_ideology_lower + nonpartisan_ideology_upper + nonpartisan_ideology_lower + retention_ideology_lower + retention_ideology_upper + Professionalization,
                     data = count_data2)

summary(curbs2_full.nb) # none of my important variables are predictive
```


# Post-Steigerwalt Meeting (End of November 2018)

Suggestions from Steigerwalt:

* What percentage of all legislation that year that deal with courts are court curbing bills (4 court curbing out of 20 bills)?  Run a regression with that
* Do unified/divided instead of the republican/democratic/split
* map out upper and partisan interaction (plot it out).  This applies, right now, to the count models
* Question: is the full model overfitted?

## Doing Unified government

Full model
```{r}
curbs_unified.nb <- glm.nb(curbs ~ Moralistic + Traditionalistic + unified + court_lower_dist + court_upper_dist + elected + elected_ideology_upper + elected_ideology_lower + Professionalization,
                     data = count_data2)

summary(curbs_unified.nb) # traditionalistic, professionalization, and unified are significant and positive.
```


## Percentage of all legislation that year
```{r}
percent_curbing <- gavelCultureControl %>%
  group_by(Fullstate, Year) %>%
  summarise(percentage = sum(curbing)/n()) 
  
percent_curbing <- percent_curbing %>%
  left_join(count_data, by = c("Fullstate", "Year")) %>%
  dplyr::select(-5:-6, -9:-17) 

percent_curbing
```

One of the first things I notice is that Alaska in 2017 has a score of 1, but that is really only because in 2017 there is only one bill that is dealing with the courts and that is a curbing bill.  How should that really be counted?  It feels like there should be some kind of weighting measure, but will have to discuss with Steigerwalt.
```{r}
gavelCultureControl %>%
  filter(Fullstate == "Alaska" & Year == 2017)
```



It appears, from the graph below, that there is a slight difference in the means between the two.  A simple t-test should show us that.
```{r}
percent_curbing %>%
  filter(!is.na(Elected)) %>%
  ggplot() +
    geom_histogram(aes(percentage, y = ..density.., fill = Elected)) +
    facet_wrap(~ Elected)
```


A simple t-test shows that there is a statistically significant differnece between the two and that the mean of Elected states is significantly higher than the mean of appointed courts.
```{r}
t.test(percentage ~ Elected, data = percent_curbing)
```

Now let's try a simple linear model:

```{r}
percent_md <- lm(percentage ~ Elected, data = percent_curbing)
summary(percent_md)
```

Now we are starting to get some significance.  Let's start with some more variables and see what happens

```{r}
percent_md_1 <- lm(percentage ~ elected + court_upper_dist + court_lower_dist, 
                    data = percent_curbing)
summary(percent_md_1) # elected is still significant and positive
```

Adding in interaction terms
```{r}
percent_md_2 <- lm(percentage ~ elected + court_upper_dist + court_lower_dist + elected_ideology_upper + elected_ideology_lower, 
                    data = percent_curbing)

summary(percent_md_2) # elected is still positive and significant.  Nothing else is close
```
Adding in political culture
```{r}
percent_md_3 <- lm(percentage ~ elected + court_upper_dist + court_lower_dist + elected_ideology_upper + elected_ideology_lower +
                     Moralistic + Traditionalistic, 
                    data = percent_curbing)
summary(percent_md_3) # election is still positive and significant.  Nothing else is. 
```

adding in professionalization
```{r}
percent_md_4 <- lm(percentage ~ elected + court_upper_dist + court_lower_dist + elected_ideology_upper + elected_ideology_lower +
                     Moralistic + Traditionalistic + Professionalization, 
                    data = percent_curbing)

summary(percent_md_4) # elected is positive and significant.  Professionalization is positive and significant
```

adding in unified government.  This would constitute the full model
```{r}
percent_curbing <- percent_curbing %>%
  mutate(unified = ifelse(SplitLegislature == 0, 1, 0))

percent_md_5 <- lm(percentage ~ elected + court_upper_dist + court_lower_dist + elected_ideology_upper + elected_ideology_lower +
                     Moralistic + Traditionalistic + Professionalization + unified, 
                    data = percent_curbing)
summary(percent_md_5) # elected hangs on at the .1 significance level.  Traditionalistic is positive and sig at .1, professionalization is positive and sig at .1, unified is negative (DON'T KNOW WHY) and significant at .05.
```

Takeaway: Elected really is significant and robust to multiple variations.

```{r}
percent_curbing2 <- percent_curbing %>%
  filter(!is.na(Elected)) %>%
  filter(!(Year %in% c("2007", "43147", "2013", "2014", "2015", "2016", "2017", "2018")))  # filtering out bad data

percent_curbing2

percent_md_6 <- lm(percentage ~ elected + court_upper_dist + court_lower_dist + elected_ideology_upper + elected_ideology_lower +
                     Moralistic + Traditionalistic + Professionalization + unified, 
                    data = percent_curbing2) # full model, not good

percent_md_7 <- lm(percentage ~ elected, 
                    data = percent_curbing2)
summary(percent_md_7)

percent_md_8 <- lm(percentage ~ elected + court_upper_dist + court_lower_dist, 
                    data = percent_curbing2)
summary(percent_md_8)

percent_md_9 <- lm(percentage ~ elected + court_upper_dist + court_lower_dist + elected_ideology_upper + elected_ideology_lower, 
                    data = percent_curbing2)
summary(percent_md_9) # nothing sig

percent_md_10 <- lm(percentage ~ elected + court_upper_dist + court_lower_dist + elected_ideology_upper + elected_ideology_lower + Moralistic + Traditionalistic, 
                    data = percent_curbing2)
summary(percent_md_10) # nothing sig

percent_md_11 <- lm(percentage ~ elected + court_upper_dist + court_lower_dist + elected_ideology_upper + elected_ideology_lower + Moralistic + Traditionalistic + Professionalization, 
                    data = percent_curbing2) # professionalization is sig
summary(percent_md_11)
```


### takeaway

Using less data (fewer years), the model is no longer significant.  DO IDEOLOGY WITH FEWER YEARS (MORE PROPER), THEN DO FULLER MODELS WITHOUT IDEOLOGY.

# Final Models:

I will use these as the official models with the broken down models in an appendix.

## Final Models - Percentage DV
```{r}
## Shorter years
summary(percent_md_7) # just elected
summary(percent_md_8) # elected and ideology
summary(percent_md_9) # elected interacted with ideology nothing sig
summary(percent_md_6) # full model with ideology and shorter years


## Full years, no ideology
percent_md_no_id_1 <- lm(percentage ~ elected + Moralistic + Traditionalistic + Professionalization + unified, data = percent_curbing)
summary(percent_md_no_id_1) # full model (excluding ideology)

percent_md_no_id_2 <- lm(percentage ~ elected, data = percent_curbing)
summary(percent_md_no_id_2) # sig, by itself
```


### Predictions

```{r}
percent_curbing2_predictions <- percent_curbing2 %>%
  add_predictions(percent_md_6)

ggplot(data = percent_curbing2_predictions) +
  geom_boxplot(aes(x = as.factor(Professionalization), y = pred)) +
  xlab("Level of Professionalization") +
  ylab("Predicted Proportion")

ggplot(data = percent_curbing2_predictions) +
  geom_boxplot(aes(x = as.factor(elected), y = pred)) +
  ylab("Predicted Proportion") +
  xlab("Elected Versus Appointed") +
  scale_x_discrete(labels = c("0" = "Appointed", "1" = "Elected"))

j <- ggplot(data = percent_curbing2_predictions) +
  geom_point(aes(x = court_lower_dist, y = pred)) +
  ylab("Predicted Proportion") +
  xlab("Ideological Distance from Lower Chamber")

k <- ggplot(data = percent_curbing2_predictions) +
  geom_point(aes(x = court_upper_dist, y = pred)) +
  ylab("Predicted Proportion") +
  xlab("Ideological Distance from Upper Chamber")
  
grid.arrange(j, k)


## without ideology
percent_curbing_predictions <- percent_curbing %>%
  add_predictions(percent_md_no_id_1)

ggplot(data = percent_curbing_predictions) +
  geom_boxplot(aes(x = as.factor(Professionalization), y = pred)) +
  xlab("Level of Professionalization") +
  ylab("Predicted Proportion")


ggplot(data = percent_curbing_predictions) +
  geom_boxplot(aes(x = as.factor(elected), y = pred)) +
  xlab("Elected Versus Appointed") +
  ylab("Predicted Proportion") +
  scale_x_discrete(labels = c("0" = "Appointed", "1" = "Elected"))

```

## Final Models - Count

```{r}
# shorter years (with ideology included)
summary(curbs_unified.nb) # full model
exp(curbs_unified.nb$coefficients)


curbs2.elected0.nb <- glm.nb(curbs ~ elected, data = count_data2)
summary(curbs2.elected0.nb) # just elected

summary(curbs2.elected1.nb) # elected and ideology (no iteractions)
summary(curbs2.elected2.nb) # elected and ideology (interacted)

exp(curbs2.elected1.nb$coefficients)

# longer years (no ideology)
summary(curbs.elected.nb) # just elected

curbs.elected.unified.nb <- glm.nb(curbs ~ Moralistic + Traditionalistic + unified +  elected + Professionalization,
                     data = count_data)
summary(curbs.elected.unified.nb) # full model
exp(curbs.elected.unified.nb$coefficients)
```



### Adding predictions for Count Data

```{r}
count_data2_predictions <- count_data2 %>%
  add_predictions(curbs_unified.nb)

ggplot(data = count_data2_predictions) +
  geom_boxplot(aes(x = as.factor(Professionalization), y = pred)) +
  ylab("Predicted Count") +
  xlab("Level of Professionalization")

ggplot(data = count_data2_predictions) +
  geom_boxplot(aes(x = as.factor(elected), y = pred)) +
  ylab("Predicted Count") +
  xlab("Elected Versus Appointed") +
  scale_x_discrete(labels = c("0" = "Appointed", "1" = "Elected"))

l <- ggplot(data = count_data2_predictions) +
  geom_point(aes(x = court_lower_dist, y = pred)) +
  ylab("Predicted Count") +
  xlab("Ideological Distance from Lower Chamber")


m <- ggplot(data = count_data2_predictions) +
  geom_point(aes(x = court_upper_dist, y = pred)) +
  ylab("Predicted Count") +
  xlab("Ideological Distance from Upper Chamber")

grid.arrange(l, m)

grid <- count_data2 %>%
  data_grid(court_upper_dist, .model = curbs_unified.nb) %>%
  add_predictions(curbs_unified.nb)


ggplot(grid, aes(court_upper_dist, pred)) +
  geom_point() +
  ylab("Predicted Count") +
  xlab("Simulated Ideological Distance from Upper Chamber")


# Now without ideology 
count_data_predictions <- count_data %>%
  add_predictions(curbs.elected.unified.nb) 

# added jitter because it was so weird
ggplot(data = count_data_predictions) +
  geom_boxplot(aes(x = as.factor(Professionalization), y = pred)) +
  ylab("Predicted Count") +
  xlab("Level of Professinalization") +
  geom_jitter(aes(x = as.factor(Professionalization), y = pred))

ggplot(data = count_data_predictions) +
  geom_boxplot(aes(x = as.factor(elected), y = pred)) +
  ylab("Predicted Count") +
  xlab("Elected Versus Appointed") +
  scale_x_discrete(labels = c("0" = "Appointed", "1" = "Elected"))
  
```

## Model diagnostics

### No Ideology:
Adding the predicted and residual values
```{r}
percent_curbing  <- percent_curbing %>%
  filter(!is.na(Elected)) %>%
  add_predictions(percent_md_no_id_1) %>%
  add_residuals(percent_md_no_id_1) %>%
  filter(!is.na(resid))
```

Checking normal distribution.  It is pretty good, but there are some outliers at the far right.  The mean of the residual is: `r mean(percent_curbing$resid)` which is rather small. 
```{r}
ggplot(percent_curbing, aes(resid)) +
  geom_histogram()
```

```{r}
plot(percent_md_no_id_1)
```


### Shorter years, but ideology

```{r}
percent_curbing2  <- percent_curbing2 %>%
  filter(!is.na(Elected)) %>%
  add_predictions(percent_md_6) %>%
  add_residuals(percent_md_6) %>%
  filter(!is.na(resid))
```


Checking normal distribution.  It is pretty good, but there are some outliers at the far right.  The mean of the residual is: `r mean(percent_curbing2$resid)` which is rather small. 
```{r}
ggplot(percent_curbing2, aes(resid)) +
  geom_histogram()
```

```{r}
plot(percent_md_6)
```

It does struggle on the outer edges of X.


### Concerns with the proportion DV

I am worried that the proportion of all court curbing legislation in one year for a given state is so small that changing the numerator by 1 will produce wild swings.  Let's check this out:

```{r}
d <- ggplot(percent_curbing) +
  geom_histogram(aes(x = percentage, y = ..density..)) +
  labs(x = "Proportion of Bills that Curb Courts")
```

The chart above shows the distribution of proportions.  This is somewhat unsuripring in the distribution, but now lets look at the total number of legislation in a given year.

```{r}
bills_state_year <- gavelFull %>%
  group_by(Fullstate, Year) %>%
  count()
  
e <- ggplot(bills_state_year) +
  geom_histogram(aes(x = n, y = ..density..)) +
  labs(x = "Number of Bills in a Year")

gridExtra::grid.arrange(d, e, ncol = 2)
```

There graph shows that while there are instances of a large number of legislation concerning the court, the median is `r median(bills_state_year$n)` with a mode of 1.  


## Testing out the idea of splitting up the electoral variable

This is primarily in response to the poor showing of election.
```{r}
test <- glm.nb(curbs ~ Moralistic + Traditionalistic + unified +  partisan + nonpartisan + retention + Professionalization,
                     data = count_data)
summary(test)

test2 <- glm.nb(curbs ~ partisan + nonpartisan + retention,
                     data = count_data)
summary(test2)

```




